import torch
import os
import numpy as np
import re
import glob

# ================= âš™ï¸ é…ç½®åŒºåŸŸ (è¯·ä»”ç»†æ ¸å¯¹è·¯å¾„) =================

# âš ï¸ æ³¨æ„ï¼šè¯·ç¡®è®¤ VFPT çš„æ–‡ä»¶å¤¹åç§°æ˜¯å¦æ­£ç¡®
# å¦‚æœä½ ä¹‹å‰è·‘ VFPT å¤ç°æ—¶ç”¨çš„ OUTPUT_DIR æ˜¯ "./output_experiment/cifar100_vfpt"
# å¹¶ä¸”è·‘å®Œäº†5æ¬¡æœ€ç»ˆæµ‹è¯•ï¼Œé‚£ä¹ˆç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶å¤¹åé€šå¸¸æ˜¯ "./output_experiment/cifar100_vfpt_finalfinal"

experiments = {
    # ------------------- CIFAR-100 -------------------
    "CIFAR-100 [Baseline]":   "./output_experiment/cifar100_vpt_baseline_finalfinal",
    "CIFAR-100 [VFPT]":       "./output_experiment/cifar100_gpu_test_finalfinal", 
    "CIFAR-100 [DCT+Gating]": "./output_experiment/cifar100_vfpt_dct_gating_finalfinal",
    
    # ------------------- EuroSAT -------------------
    "EuroSAT [Baseline]":     "./output_experiment/eurosat_vpt_baseline_finalfinal",
    "EuroSAT [VFPT]":         "./output_experiment/eurosat_test_finalfinal",  
    "EuroSAT [DCT+Gating]":   "./output_experiment/eurosat_vfpt_dct_gating_finalfinal",

    # ------------------- CLEVR -------------------
    "CLEVR [Baseline]":       "./output_experiment/clevr_vpt_baseline_finalfinal",
    "CLEVR [VFPT]":           "./output_experiment/clevr_test_finalfinal",   
    "CLEVR [DCT+Gating]":     "./output_experiment/clevr_vfpt_dct_gating_finalfinal",
}

# ==========================================================

def find_result_folder(base_dir):
    """
    è‡ªåŠ¨å¯»æ‰¾åŒ…å« eval_results.pth çš„ run1 æ–‡ä»¶å¤¹çš„ä¸Šçº§ç›®å½•ã€‚
    """
    # æœç´¢æ¨¡å¼: base_dir/**/run1/eval_results.pth
    search_pattern = os.path.join(base_dir, "**", "run1", "eval_results.pth")
    matches = glob.glob(search_pattern, recursive=True)
    
    if not matches:
        return None
    
    # å›é€€ä¸¤å±‚å¾—åˆ° lr_wd é‚£ä¸€å±‚çš„è·¯å¾„
    run1_path = os.path.dirname(matches[0]) 
    lr_wd_path = os.path.dirname(run1_path) 
    return lr_wd_path

def get_epoch_num(key_str):
    match = re.search(r'epoch_(\d+)', key_str)
    return int(match.group(1)) if match else -1

def analyze_single_experiment(name, base_path):
    print(f"\nğŸŒ æ­£åœ¨åˆ†æ: {name}")
    
    if not os.path.exists(base_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨ (è·³è¿‡): {base_path}")
        return None

    # 1. è‡ªåŠ¨å®šä½
    target_dir = find_result_folder(base_path)
    if not target_dir:
        print(f"âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ (eval_results.pth)ï¼Œè¯·æ£€æŸ¥æ˜¯å¦è·‘å®Œ: {base_path}")
        return None
        
    print(f"ğŸ“ è·¯å¾„ç¡®è®¤: {target_dir}")
    print("-" * 65)
    print(f"{'Run ID':<10} | {'æœ€ç»ˆç²¾åº¦ (Final)':<18} | {'æœ€é«˜ç²¾åº¦ (Peak)':<18} | {'å›è½ (Drop)':<10}")
    print("-" * 65)

    final_accs = []
    peak_accs = []

    # éå† run1 åˆ° run5
    for i in range(1, 6):
        run_folder = os.path.join(target_dir, f"run{i}")
        result_file = os.path.join(run_folder, "eval_results.pth")
        
        if os.path.exists(result_file):
            try:
                data = torch.load(result_file, map_location="cpu")
                epoch_data = {} 
                
                # è§£ææ•°æ®
                for key, value in data.items():
                    if "epoch" in key and "classification" in value:
                        cls_res = value["classification"]
                        test_key = next((k for k in cls_res.keys() if "test" in k), None)
                        if not test_key:
                            test_key = next((k for k in cls_res.keys() if "val" in k), None)

                        if test_key:
                            acc = float(cls_res[test_key]["top1"]) * 100
                            epoch_num = get_epoch_num(key)
                            epoch_data[epoch_num] = acc
                
                if not epoch_data:
                    print(f"{f'Run {i}':<10} | {'æ•°æ®ä¸ºç©º':<18} | {'-':<18} | {'-':<10}")
                    continue

                last_epoch = max(epoch_data.keys())
                final_acc = epoch_data[last_epoch]
                peak_acc = max(epoch_data.values())
                drop = peak_acc - final_acc
                
                final_accs.append(final_acc)
                peak_accs.append(peak_acc)
                
                print(f"{f'Run {i}':<10} | {final_acc:.2f}% (ep{last_epoch})     | {peak_acc:.2f}%             | -{drop:.2f}%")

            except Exception as e:
                print(f"Run {i}: è¯»å–é”™è¯¯ - {e}")
        else:
            print(f"{f'Run {i}':<10} | {'æœªæ‰¾åˆ°æ–‡ä»¶':<18} | {'-':<18} | {'-':<10}")

    print("-" * 65)
    
    if final_accs:
        return {
            "name": name,
            "final_avg": np.mean(final_accs),
            "final_std": np.std(final_accs),
            "peak_avg": np.mean(peak_accs),
            "peak_std": np.std(peak_accs)
        }
    return None

# ================= ä¸»ç¨‹åº =================

results_summary = []

for exp_name, exp_path in experiments.items():
    res = analyze_single_experiment(exp_name, exp_path)
    if res:
        results_summary.append(res)

print("\n\n" + "="*85)
print(f"{'ğŸ“Š ä¸‰ç§æ–¹æ³•å¯¹æ¯”å®éªŒç»“æœæ±‡æ€»':^75}")
print("="*85)
print(f"{'å®éªŒåç§°':<25} | {'æœ€ç»ˆç²¾åº¦ (Final Accuracy)':<30} | {'å³°å€¼ç²¾åº¦ (Peak Accuracy)':<30}")
print("-" * 85)

# æŒ‰æ•°æ®é›†åˆ†ç»„æ‰“å°ï¼Œæ–¹ä¾¿å¯¹æ¯”
current_dataset = ""
for res in results_summary:
    # æå–æ•°æ®é›†åç§° (å¦‚ CIFAR-100)
    dataset_name = res['name'].split(" [")[0]
    if dataset_name != current_dataset:
        if current_dataset != "": print("-" * 85)
        current_dataset = dataset_name
    
    final_str = f"{res['final_avg']:.2f}% Â± {res['final_std']:.2f}%"
    peak_str = f"{res['peak_avg']:.2f}% Â± {res['peak_std']:.2f}%"
    print(f"{res['name']:<25} | {final_str:<30} | {peak_str:<30}")

print("="*85)